# Conversational speech transcription using context-dependent deep neural networks 

* Motivation: Trying to apply Context-Dependent Deep-Neural-Network HMM (CD-DNN-HMM) directly to speech-to-text transcription
* Contribution: 
  CD-DNN-HMM can be used in large-scale tasks, We can reduce error and model size by applying weight sparseness, Look at MLP and DBN (deep belief network) to see what affects the accuracy of CD-DNN-HMMs 

* Method: 
* Results: 
* Future work: 

## Related work
- Yu et al. Roles of Pretraining and Fine-Tuning in Context-Dependent DNN-HMMs for Real-World Speech Recognition [[paper]]() [[notes]]() : States use of CD-DNN-HMMs
- Dahl et al. Context-Dependent Pre-Trained Deep Neural Networks for Large Vocabulary Speech Recognition [[paper]]() [[notes]]() : States use of CD-DNN-HMMs

## Prerequisites
- CD-DNN-HMMs apply classical ANN-HMMs to traditional tied-state triphones directly, exploiting Hinton's deep-belief-network (DBN) pre-training procedure
- Yu et al. Roles of Pretraining and Fine-Tuning in Context-Dependent DNN-HMMs for Real-World Speech Recognition [[paper]]() [[notes]]() : States use of CD-DNN-HMMs
- Dahl et al. Context-Dependent Pre-Trained Deep Neural Networks for Large Vocabulary Speech Recognition [[paper]]() [[notes]]() : States use of CD-DNN-HMMs ** (see for a more detailed description) **

## Methods
- 
![alt tag](https://github.com/mjc92/studies/blob/master/notes/rnn_lowrank.JPG)
